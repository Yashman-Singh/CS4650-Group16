{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: (1600000, 6)\n"
     ]
    }
   ],
   "source": [
    "sentiment140 = pd.read_csv('data/training.1600000.processed.noemoticon.csv', encoding='latin-1', header=None)\n",
    "sentiment140.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "\n",
    "print(f\"Original dataset size: {sentiment140.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_mapping = {\n",
    "    r\"[:=]\\s*\\)+\": \"🙂\",  # handles :), =), :)), =)), : ), = )), etc.\n",
    "    r\"[:=]\\s*\\(+\": \"🙁\",  # handles :(, = (, :((, =((, etc.\n",
    "    r\"[:=]D\": \"😄\",         # handles :D, =D\n",
    "    r\"[:=]\\s*D\": \"😄\",       # handles : D, = D \n",
    "    r\"[:=]P\": \"😛\",         # handles :P, =P\n",
    "    r\"[:=]\\s*P\": \"😛\",       # handles : P, = P\n",
    "    r\"[:=]O\": \"😮\",         # handles :O, =O\n",
    "    r\"[:=]\\s*O\": \"😮\",       # handles : O, = O\n",
    "    r\";\\)\": \"😉\",             # handles ;)\n",
    "    r\";\\s*\\)\": \"😉\",         # handles ; )\n",
    "}\n",
    "\n",
    "def replace_emoticons(text):\n",
    "    for emoticon_pattern, emoji_char in emoticon_mapping.items():\n",
    "        text = re.sub(emoticon_pattern, emoji_char, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment140['text'] = sentiment140['text'].apply(replace_emoticons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with emojis after replacement: 13539\n"
     ]
    }
   ],
   "source": [
    "def contains_emoji(text):\n",
    "    for char in text:\n",
    "        if char in emoji.EMOJI_DATA:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "emoji_rows = sentiment140[sentiment140['text'].apply(contains_emoji)]\n",
    "non_emoji_rows = sentiment140[~sentiment140['text'].apply(contains_emoji)]\n",
    "\n",
    "print(f\"Rows with emojis after replacement: {len(emoji_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset size: (50000, 6)\n"
     ]
    }
   ],
   "source": [
    "needed_non_emoji_rows = max(0, 50000 - len(emoji_rows))\n",
    "\n",
    "if needed_non_emoji_rows > 0:\n",
    "    sampled_non_emoji_rows = non_emoji_rows.sample(needed_non_emoji_rows, random_state=42)\n",
    "    final_sample = pd.concat([emoji_rows, sampled_non_emoji_rows]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "else:\n",
    "    final_sample = emoji_rows.sample(50000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Final dataset size: {final_sample.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned dataset to data/sentiment140_with_emojis.csv\n"
     ]
    }
   ],
   "source": [
    "output_path = 'data/sentiment140_with_emojis.csv'\n",
    "final_sample.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Saved cleaned dataset to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    target                                               text\n",
      "0        4        It was a dark and stormy night...  love it!\n",
      "1        4  @Reynolds_x eeeep i hope we get it  paid for h...\n",
      "2        0  Feels sad my best friend Skippy is not going t...\n",
      "3        4  @Majestic76 no no hun. im serious you are beau...\n",
      "4        4  so iÂ´ll help my dad...spending a little bit t...\n",
      "5        0  couldnt understand Terminator movie :|  bobo k...\n",
      "6        4  Now I've made dinner for me and my brother  si...\n",
      "7        0  My last day on the mountian and then back to c...\n",
      "8        0          Goodnight tweeperzz haha 😉 Time to study \n",
      "9        0  @angelicajw i know just waitin on u to say som...\n",
      "10       0  haha #PakCricket is out of trending topics again \n",
      "11       4                                          @philbee \n",
      "12       4  Reading Twilight  Yep sounds good! Sad to not ...\n",
      "13       0  @GTA_Cop I agree, we wives ARE ridiculous! 😉  ...\n",
      "14       0                       just woke up sooooooo tired \n",
      "15       4       @britttnicole Good morning  Have a nice day \n",
      "16       4   on the train going up to london. Weathers fab!! \n",
      "17       0             Knows I'm sick if I don't want coffee \n",
      "18       4  @JessiieCullen AHahahs! Sure you can! 😉 Just k...\n",
      "19       4  Trying Pandora/Dora.FM thing...what will this ...\n"
     ]
    }
   ],
   "source": [
    "print(final_sample[['target', 'text']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows containing at least one emoji (final sampled): 13539 out of 50000\n"
     ]
    }
   ],
   "source": [
    "num_rows_with_emoji_final = final_sample['text'].apply(contains_emoji).sum()\n",
    "print(f\"Rows containing at least one emoji (final sampled): {num_rows_with_emoji_final} out of {len(final_sample)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
